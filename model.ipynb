{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>meal</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>IsPortugal</th>\n",
       "      <th>is_same_room_type</th>\n",
       "      <th>isChangedMade</th>\n",
       "      <th>IsGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>...</td>\n",
       "      <td>No Company</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>...</td>\n",
       "      <td>No Company</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>...</td>\n",
       "      <td>No Company</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>...</td>\n",
       "      <td>No Company</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>...</td>\n",
       "      <td>No Company</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hotel  is_canceled  lead_time  stays_in_weekend_nights  \\\n",
       "0  Resort Hotel            0          7                        0   \n",
       "1  Resort Hotel            0         13                        0   \n",
       "2  Resort Hotel            0         14                        0   \n",
       "3  Resort Hotel            0         14                        0   \n",
       "4  Resort Hotel            0          0                        0   \n",
       "\n",
       "   stays_in_week_nights  adults  children  babies meal country  ...  \\\n",
       "0                     1       1       0.0       0   BB     GBR  ...   \n",
       "1                     1       1       0.0       0   BB     GBR  ...   \n",
       "2                     2       2       0.0       0   BB     GBR  ...   \n",
       "3                     2       2       0.0       0   BB     GBR  ...   \n",
       "4                     2       2       0.0       0   BB     PRT  ...   \n",
       "\n",
       "      company days_in_waiting_list  customer_type    adr  \\\n",
       "0  No Company                    0      Transient   75.0   \n",
       "1  No Company                    0      Transient   75.0   \n",
       "2  No Company                    0      Transient   98.0   \n",
       "3  No Company                    0      Transient   98.0   \n",
       "4  No Company                    0      Transient  107.0   \n",
       "\n",
       "   required_car_parking_spaces total_of_special_requests IsPortugal  \\\n",
       "0                            0                         0          0   \n",
       "1                            0                         0          0   \n",
       "2                            0                         1          0   \n",
       "3                            0                         1          0   \n",
       "4                            0                         0          1   \n",
       "\n",
       "   is_same_room_type isChangedMade IsGroup  \n",
       "0              False         False   False  \n",
       "1               True         False   False  \n",
       "2               True         False   False  \n",
       "3               True         False   False  \n",
       "4               True         False   False  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('hotel_bookings_clean.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test set tratified by deposit_type\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(dataset, dataset['deposit_type']):\n",
    "    strat_train_set = dataset.loc[train_index]\n",
    "    strat_test_set = dataset.loc[test_index]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop deposit_type from train and test set\n",
    "\n",
    "# strat_train_set.drop('deposit_type', axis=1, inplace=True)\n",
    "# strat_test_set.drop('deposit_type', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = strat_train_set.drop('is_canceled', axis=1)\n",
    "y_train = strat_train_set['is_canceled']\n",
    "\n",
    "X_test = strat_test_set.drop('is_canceled', axis=1)\n",
    "y_test = strat_test_set['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OrdinalEncoder to encode categorical variables\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "for col in cat_cols:\n",
    "    encoder.fit(dataset[col].values.reshape(-1, 1))\n",
    "    X_train[col] = encoder.transform(X_train[col].values.reshape(-1, 1))\n",
    "    X_test[col] = encoder.transform(X_test[col].values.reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Baseline model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8035776817004857"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    solver='liblinear', random_state=42, max_iter=1000\n",
    ")\n",
    "scores = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Xgboost model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757413488290325"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    " \n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8770456687516065"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model on the test set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8884699968583097"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_on_train = model.predict(X_train)\n",
    "\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_train, y_pred_on_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is not overfitting so much, the result are quite good on the test set too so it's interesting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8768880263268922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance of feature deposit_type: 0.5256\n",
      "Importance of feature required_car_parking_spaces: 0.0997\n",
      "Importance of feature is_same_room_type: 0.0913\n",
      "Importance of feature market_segment: 0.0540\n",
      "Importance of feature IsPortugal: 0.0525\n",
      "Importance of feature previous_cancellations: 0.0309\n",
      "Importance of feature total_of_special_requests: 0.0264\n",
      "Importance of feature customer_type: 0.0163\n",
      "Importance of feature agent: 0.0153\n",
      "Importance of feature previous_bookings_not_canceled: 0.0102\n",
      "Importance of feature distribution_channel: 0.0097\n",
      "Importance of feature booking_changes: 0.0085\n",
      "Importance of feature lead_time: 0.0081\n",
      "Importance of feature country: 0.0059\n",
      "Importance of feature IsGroup: 0.0052\n",
      "Importance of feature days_in_waiting_list: 0.0051\n",
      "Importance of feature adults: 0.0042\n",
      "Importance of feature children: 0.0036\n",
      "Importance of feature meal: 0.0036\n",
      "Importance of feature adr: 0.0033\n",
      "Importance of feature stays_in_weekend_nights: 0.0031\n",
      "Importance of feature hotel: 0.0030\n",
      "Importance of feature assigned_room_type: 0.0029\n",
      "Importance of feature is_repeated_guest: 0.0025\n",
      "Importance of feature stays_in_week_nights: 0.0025\n",
      "Importance of feature company: 0.0024\n",
      "Importance of feature babies: 0.0022\n",
      "Importance of feature reserved_room_type: 0.0020\n",
      "Importance of feature isChangedMade: 0.0000\n"
     ]
    }
   ],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "for i in sorted_idx:\n",
    "    print(f\"Importance of feature {X_train.columns[i]}: {feature_importances[i]:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights from Feature Importance Analysis\n",
    "\n",
    "1. **Major Impact of `deposit_type` (0.5256)**: The `deposit_type` feature stands out as the most significant predictor in our model.\n",
    "\n",
    "2. **High Relevance of `required_car_parking_spaces` (0.0997)**: As we noticed during EDA the `required_car_parking_spaces` feature give interesting insights. It is the second most important feature in our model.\n",
    "\n",
    "3. **Significant Influence of Custom Features**: Both `IsPortugal` and `is_same_room_type`, features that we engineered, show considerable importance in the model. This reveals that both the geographical origin of the guest and the consistency in room allocation (whether the assigned room type matches the reserved room type) are influential factors in predicting cancellations.\n",
    "\n",
    "4. **Observation on `IsChangedMade`**: Interestingly, the `IsChangedMade` feature, which we created to capture whether a booking has been modified at least once, shows no significance in our model. This could suggest that the information is better captured by other features like `booking_changes`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      7277\n",
      "           1       0.86      0.81      0.83      4394\n",
      "\n",
      "    accuracy                           0.88     11671\n",
      "   macro avg       0.87      0.86      0.87     11671\n",
      "weighted avg       0.88      0.88      0.88     11671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classificaion report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of Results\n",
    "\n",
    "These results are quite good\n",
    "\n",
    "- The high precision for non-cancellations (Class 0) suggests that when our model predicts a booking will not be canceled, it is likely correct.\n",
    "- The recall for cancellations (Class 1) is slightly lower, indicating that our model miss more cancellations than non-cancellations.\n",
    "- The F1-scores for both classes are relatively high, indicating a good balance between precision and recall for both classes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Decision Tree model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8565008695284577"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=None,\n",
    "    max_features=0.7,\n",
    "    min_samples_split=25,\n",
    "    min_samples_leaf=1\n",
    ")\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "scores.mean()\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have configured our Decision Tree Classifier with specific hyperparameters to optimize its performance. Here's a brief summary of each hyperparameter and its role in the model:\n",
    "\n",
    "- **`max_depth=None`**: Allows the tree to grow as deep as necessary. Without a maximum depth, the tree keeps expanding until all leaves contains element o only 1 class or until all leaves contain less than `min_samples_split` samples.\n",
    "\n",
    "- **`max_features=0.7`**: The fraction of features to be considered when looking for the best split. Here, 70% of the features are randomly sampled for each split decision, adding randomness to the model and potentially improving generalization.\n",
    "\n",
    "- **`min_samples_split=25`**: The minimum number of samples required to split an internal node. A higher value prevents the model from learning overly specific patterns and helps in controlling overfitting.\n",
    "\n",
    "- **`min_samples_leaf=1`**: The minimum number of samples required to be at a leaf node. A smaller leaf size gives the model more flexibility in learning the data but can also lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171164995858682"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train accuracy\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of Results\n",
    "\n",
    "The results are not as good as the Xgboost model, we immediately see that the model is overfitting a lot, Bagging could be a solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "for col in num_cols:\n",
    "    X_train[col] = scaler.fit_transform(X_train[col].values.reshape(-1, 1))\n",
    "    X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873370569981189"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8912689572444521"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model on the test set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8912689572444521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   1.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=4, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8919544169308542"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "gs_model = GridSearchCV(estimator=model,\n",
    "                        param_grid=param_grid,\n",
    "                        cv=3,\n",
    "                        verbose=2)\n",
    "\n",
    "X_train_reduced = X_train[:20000]\n",
    "y_train_reduced = y_train[:4000]\n",
    "\n",
    "gs_model.fit(X_train, y_train)\n",
    " \n",
    "gs_model.best_params_\n",
    " \n",
    "gs_model.score(X_test, y_test)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Hyperparameter Grid\n",
    "\n",
    "- **`n_estimators`**: [100, 300, 500]  \n",
    "  The number of trees in the forest. More trees can lead to better performance but also increase computation time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8919544169308542"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get best model\n",
    "best_model = gs_model.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      7277\n",
      "           1       0.88      0.83      0.85      4394\n",
      "\n",
      "    accuracy                           0.89     11671\n",
      "   macro avg       0.89      0.88      0.88     11671\n",
      "weighted avg       0.89      0.89      0.89     11671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classificaion report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Interpretation\n",
    "\n",
    "These results are simalr to xgboost but better \n",
    "\n",
    "- All metrics have improved compared to the the xgboost model.\n",
    "- f1 score for class 1 has improved from 0.83 to 0.85.\n",
    "- f1 score for class 0 has improved from 0.90 to 0.91.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
